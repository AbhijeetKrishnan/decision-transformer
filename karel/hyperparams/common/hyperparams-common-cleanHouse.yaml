# Hyperparameters for training a decision transformer on the cleanHouse Karel task
# found by tuning using Optuna, but manually edited to be somewhere near the
# mean for all tasks
%YAML 1.1
---
task:
  env: karel
  karel_task: topOff
  dataset: playback
  seed: 75092
  num_eval_episodes: 64
  eval_seeds: [70965,  85006, 50916, 57114, 91771] # unused
training:
  env_targets: [2.2]
  scale: 1.0
  mode: delayed
  device: cuda
  model_type: dt
  log_to_wandb: true
  format: h5
hyperparams:
  K: 50
  pct_traj: 0.01
  batch_size: 64
  embed_dim: 128
  n_layer: 3
  n_head: 2
  dropout: 0.05
  learning_rate: 1.0e-3
  weight_decay: 5.0e-4
  warmup_steps: 200
  max_iters: 10
  num_steps_per_iter: 500
  use_seq_state_embedding: true
  gru_hidden_size: 512
  gru_num_layers: 1
  gru_dropout: 0.05
  sample: reward
...